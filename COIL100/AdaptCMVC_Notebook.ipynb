{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AdaptCMVC - 增量视图聚类\n",
        "\n",
        "本 Notebook 将 AdaptCMVC 的训练流程转换为分步执行，方便调试和检查。\n",
        "\n",
        "**优点：**\n",
        "- ✅ 分步执行，可以随时停止和继续\n",
        "- ✅ 每步完成后保存检查点，不会丢失进度\n",
        "- ✅ 可视化中间结果\n",
        "- ✅ 方便调试和修改参数\n",
        "\n",
        "## 项目流程\n",
        "\n",
        "1. **源模型训练** (`source.py`)：训练初始的 VAE 模型\n",
        "2. **增量视图适配** (`main.py`)：逐步适配新视角\n",
        "   - View 1：从源模型开始\n",
        "   - View 2：从 View 1 的最佳模型开始\n",
        "   - ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 配置和初始化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 检测到 GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
            "   CUDA 版本: 11.6\n",
            "   GPU 数量: 1\n",
            "✅ 库导入成功\n"
          ]
        }
      ],
      "source": [
        "# 导入必要的库\n",
        "import logging\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# 导入 torch 来检测 GPU 可用性\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# 自动检测 GPU 可用性（优先使用 GPU，无 GPU 时回退到 CPU）\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "\n",
        "# 导入项目模块\n",
        "from robustbench.data import load_multiview\n",
        "from robustbench.sim_utils import clean_accuracy_target as accuracy_target\n",
        "from robustbench.base_model import ConsistencyAE\n",
        "import cotta\n",
        "from data_load import get_val_transformations, get_train_dataset\n",
        "\n",
        "# 配置日志\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "if USE_GPU:\n",
        "    print(f\"✅ 检测到 GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   CUDA 版本: {torch.version.cuda}\")\n",
        "    print(f\"   GPU 数量: {torch.cuda.device_count()}\")\n",
        "else:\n",
        "    print(\"⚠️  未检测到 GPU，将使用 CPU\")\n",
        "print(\"✅ 库导入成功\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 使用设备: cuda:0 (GPU: NVIDIA GeForce RTX 4060 Laptop GPU)\n",
            "✅ 随机种子设置为: 3407\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 配置参数（根据你的需求修改）\n",
        "# ========================================\n",
        "\n",
        "class Args:\n",
        "    \"\"\"参数配置类\"\"\"\n",
        "    def __init__(self):\n",
        "        # 基本参数\n",
        "        self.alpha = 0.1\n",
        "        # 根据是否有 GPU 调整批次大小（GPU 可用更大批次）\n",
        "        self.BATCH_SIZE = 32 if USE_GPU else 16\n",
        "        self.consis = 5\n",
        "        self.N = 1\n",
        "        self.sample_num_each_clusters = 15\n",
        "        self.contra = 0.5\n",
        "        self.temperature = 0.5\n",
        "        self.up_alpha = 0.2\n",
        "        \n",
        "        # 系统参数\n",
        "        self.cuda_device = '0' if USE_GPU else 'cpu'\n",
        "        self.seed = 3407\n",
        "        self.CROP_SIZE = 64\n",
        "        self.ADAPTATION = 'cotta'\n",
        "        self.name = 'coil-100'\n",
        "        self.root = 'MyData'\n",
        "        self.views = 3  # 总共 3 个视角\n",
        "        self.NUM_EX = 1920\n",
        "        self.class_num = 100\n",
        "        \n",
        "        # 优化器参数\n",
        "        self.STEPS = 1\n",
        "        self.EPISODIC = False\n",
        "        self.LR = 0.0001\n",
        "        self.BETA = 0.9\n",
        "        self.WD = 0.0\n",
        "        self.METHOD = 'Adam'\n",
        "\n",
        "args = Args()\n",
        "\n",
        "# 设置设备和随机种子\n",
        "# 优先使用 GPU，如果没有 GPU 则使用 CPU\n",
        "if args.cuda_device.lower() != 'cpu' and torch.cuda.is_available():\n",
        "    device = torch.device(f'cuda:{args.cuda_device}')\n",
        "    print(f\"✅ 使用设备: {device} (GPU: {torch.cuda.get_device_name(0)})\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(f\"✅ 使用设备: {device} (CPU)\")\n",
        "\n",
        "# 设置随机种子\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available() and device.type == 'cuda':\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    if device.type == 'cuda':\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "setup_seed(args.seed)\n",
        "print(f\"✅ 随机种子设置为: {args.seed}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 辅助函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 辅助函数定义完成\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 辅助函数\n",
        "# ========================================\n",
        "\n",
        "def setup_source(model):\n",
        "    \"\"\"设置源模型（无适配）\"\"\"\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def setup_optimizer_custom(params):\n",
        "    \"\"\"设置优化器\"\"\"\n",
        "    if args.METHOD == 'Adam':\n",
        "        return optim.Adam(params,\n",
        "                    lr=args.LR,\n",
        "                    betas=(args.BETA, 0.999),\n",
        "                    weight_decay=args.WD)\n",
        "    elif args.METHOD == 'SGD':\n",
        "        return optim.SGD(params,\n",
        "                   lr=args.LR,\n",
        "                   momentum=0.9,\n",
        "                   dampening=0,\n",
        "                   weight_decay=args.WD,\n",
        "                   nesterov=True)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "def setup_cotta_model(model):\n",
        "    \"\"\"设置 CoTTA 模型\"\"\"\n",
        "    model = cotta.configure_model(model)\n",
        "    params, param_names = cotta.collect_params(model)\n",
        "    optimizer = setup_optimizer_custom(params)\n",
        "    cotta_model = cotta.CoTTA(model, optimizer,\n",
        "                           steps=args.STEPS,\n",
        "                           episodic=args.EPISODIC,\n",
        "                            num_classes = args.class_num,\n",
        "                              CROP_SIZE = args.CROP_SIZE,\n",
        "                              contra=args.contra,\n",
        "                              consis=args.consis,\n",
        "                              N=args.N,\n",
        "                              sample_num_each_clusters = args.sample_num_each_clusters)\n",
        "    return cotta_model\n",
        "\n",
        "print(\"✅ 辅助函数定义完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 步骤1：View 1 训练\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "开始 View 1 训练\n",
            "================================================================================\n",
            "✅ 已加载源模型\n",
            "✅ 已设置 CoTTA 模型\n",
            "✅ 已加载数据和先验\n",
            "\n",
            "开始训练 View 1...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# View 1: 从源模型开始训练\n",
        "# ========================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"开始 View 1 训练\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. 构建模型\n",
        "AE = ConsistencyAE(\n",
        "    basic_hidden_dim=32, c_dim=20, continous=True, in_channel=3, \n",
        "    num_res_blocks=3, ch_mult=[1, 2, 4, 8], block_size=8, temperature=1.0,\n",
        "    latent_ch=8, kld_weight=1.0, views=1, categorical_dim=args.class_num\n",
        ")\n",
        "\n",
        "# 2. 加载源模型\n",
        "AE.load_state_dict(\n",
        "    torch.load('./source_model/v1-best-2806-185-0.5641.pth', map_location=device),\n",
        "    strict=False\n",
        ")\n",
        "base_model = AE.to(device)\n",
        "print(\"✅ 已加载源模型\")\n",
        "\n",
        "# 3. 设置适配模型\n",
        "model = setup_cotta_model(base_model)\n",
        "print(\"✅ 已设置 CoTTA 模型\")\n",
        "\n",
        "# 4. 加载数据和先验\n",
        "val_transformations = get_val_transformations(args.CROP_SIZE)\n",
        "train_dataset = get_train_dataset(args.name, args.root, args.views, val_transformations)\n",
        "\n",
        "views = 1\n",
        "source_result = np.load(f'./source_model/v1-20source_result.npy')\n",
        "source_result = torch.from_numpy(source_result).to(device)\n",
        "source_center = np.load(f'./source_model/v1-20source_center.npy')\n",
        "print(\"✅ 已加载数据和先验\")\n",
        "\n",
        "print(\"\\n开始训练 View 1...\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[迭代 1/50]  consist-acc:0.5391, consist-nmi:0.7852, consist-ari:0.4438, consist-p:0.5297, consist-fscore:0.5017\n",
            "  💾 保存最佳模型: acc=0.5391, loss=2130.6047\n",
            "[迭代 2/50]  consist-acc:0.5432, consist-nmi:0.7865, consist-ari:0.4509, consist-p:0.5538, consist-fscore:0.5146\n",
            "  💾 保存最佳模型: acc=0.5432, loss=1689.3777\n",
            "[迭代 3/50]  consist-acc:0.5693, consist-nmi:0.7928, consist-ari:0.4683, consist-p:0.5832, consist-fscore:0.5380\n",
            "  💾 保存最佳模型: acc=0.5693, loss=1484.1229\n",
            "[迭代 4/50]  consist-acc:0.5562, consist-nmi:0.7959, consist-ari:0.4642, consist-p:0.5612, consist-fscore:0.5262\n",
            "  💾 保存最佳模型: acc=0.5562, loss=1369.5385\n",
            "[迭代 5/50]  consist-acc:0.5375, consist-nmi:0.7837, consist-ari:0.4249, consist-p:0.5458, consist-fscore:0.5050\n",
            "  💾 保存最佳模型: acc=0.5375, loss=1280.7312\n",
            "[迭代 6/50]  consist-acc:0.5656, consist-nmi:0.7963, consist-ari:0.4709, consist-p:0.5708, consist-fscore:0.5355\n",
            "  💾 保存最佳模型: acc=0.5656, loss=1217.0215\n",
            "[迭代 7/50]  consist-acc:0.5797, consist-nmi:0.7985, consist-ari:0.4797, consist-p:0.5770, consist-fscore:0.5514\n",
            "  💾 保存最佳模型: acc=0.5797, loss=1156.1964\n",
            "[迭代 8/50]  consist-acc:0.5625, consist-nmi:0.7928, consist-ari:0.4698, consist-p:0.5591, consist-fscore:0.5241\n",
            "  💾 保存最佳模型: acc=0.5625, loss=1111.0988\n",
            "[迭代 9/50]  consist-acc:0.5682, consist-nmi:0.7908, consist-ari:0.4715, consist-p:0.5604, consist-fscore:0.5371\n",
            "  💾 保存最佳模型: acc=0.5682, loss=1069.2242\n",
            "[迭代 10/50]  consist-acc:0.5516, consist-nmi:0.7831, consist-ari:0.4397, consist-p:0.5729, consist-fscore:0.5245\n",
            "  💾 保存最佳模型: acc=0.5516, loss=1042.5214\n",
            "[迭代 11/50]  consist-acc:0.5656, consist-nmi:0.7970, consist-ari:0.4747, consist-p:0.5733, consist-fscore:0.5335\n",
            "[迭代 12/50]  consist-acc:0.5448, consist-nmi:0.7854, consist-ari:0.4390, consist-p:0.5654, consist-fscore:0.5137\n",
            "  💾 保存最佳模型: acc=0.5448, loss=1039.1162\n",
            "[迭代 13/50]  consist-acc:0.5505, consist-nmi:0.7888, consist-ari:0.4382, consist-p:0.5582, consist-fscore:0.5177\n",
            "  💾 保存最佳模型: acc=0.5505, loss=1037.6663\n",
            "[迭代 14/50]  consist-acc:0.5464, consist-nmi:0.7883, consist-ari:0.4429, consist-p:0.5525, consist-fscore:0.5157\n",
            "[迭代 15/50]  consist-acc:0.5526, consist-nmi:0.7863, consist-ari:0.4404, consist-p:0.5621, consist-fscore:0.5236\n",
            "  💾 保存最佳模型: acc=0.5526, loss=992.4262\n",
            "[迭代 16/50]  consist-acc:0.5427, consist-nmi:0.7876, consist-ari:0.4426, consist-p:0.5276, consist-fscore:0.5010\n",
            "  💾 保存最佳模型: acc=0.5427, loss=964.8431\n",
            "[迭代 17/50]  consist-acc:0.5516, consist-nmi:0.7885, consist-ari:0.4361, consist-p:0.5675, consist-fscore:0.5159\n",
            "[迭代 18/50]  consist-acc:0.5698, consist-nmi:0.7973, consist-ari:0.4696, consist-p:0.5677, consist-fscore:0.5354\n",
            "[迭代 19/50]  consist-acc:0.5562, consist-nmi:0.7877, consist-ari:0.4541, consist-p:0.5713, consist-fscore:0.5278\n",
            "[迭代 20/50]  consist-acc:0.5547, consist-nmi:0.7849, consist-ari:0.4499, consist-p:0.5679, consist-fscore:0.5310\n",
            "[迭代 21/50]  consist-acc:0.5693, consist-nmi:0.7855, consist-ari:0.4543, consist-p:0.5895, consist-fscore:0.5467\n",
            "  💾 保存最佳模型: acc=0.5693, loss=959.7139\n",
            "[迭代 22/50]  consist-acc:0.5708, consist-nmi:0.7922, consist-ari:0.4624, consist-p:0.5659, consist-fscore:0.5351\n",
            "  💾 保存最佳模型: acc=0.5708, loss=893.6671\n",
            "[迭代 23/50]  consist-acc:0.5635, consist-nmi:0.7813, consist-ari:0.4534, consist-p:0.5814, consist-fscore:0.5344\n",
            "  💾 保存最佳模型: acc=0.5635, loss=862.5181\n",
            "[迭代 24/50]  consist-acc:0.5646, consist-nmi:0.7871, consist-ari:0.4475, consist-p:0.5627, consist-fscore:0.5286\n",
            "  💾 保存最佳模型: acc=0.5646, loss=840.2941\n",
            "[迭代 25/50]  consist-acc:0.5542, consist-nmi:0.7920, consist-ari:0.4589, consist-p:0.5471, consist-fscore:0.5185\n",
            "[迭代 26/50]  consist-acc:0.5688, consist-nmi:0.7906, consist-ari:0.4659, consist-p:0.5634, consist-fscore:0.5372\n",
            "[迭代 27/50]  consist-acc:0.5703, consist-nmi:0.7918, consist-ari:0.4616, consist-p:0.5649, consist-fscore:0.5328\n",
            "[迭代 28/50]  consist-acc:0.5557, consist-nmi:0.7878, consist-ari:0.4548, consist-p:0.5535, consist-fscore:0.5194\n",
            "[迭代 29/50]  consist-acc:0.5271, consist-nmi:0.7792, consist-ari:0.4316, consist-p:0.5301, consist-fscore:0.4950\n",
            "[迭代 30/50]  consist-acc:0.5609, consist-nmi:0.7819, consist-ari:0.4510, consist-p:0.5416, consist-fscore:0.5285\n",
            "[迭代 31/50]  consist-acc:0.5630, consist-nmi:0.7882, consist-ari:0.4599, consist-p:0.5640, consist-fscore:0.5327\n",
            "[迭代 32/50]  consist-acc:0.5667, consist-nmi:0.7974, consist-ari:0.4807, consist-p:0.5647, consist-fscore:0.5308\n",
            "[迭代 33/50]  consist-acc:0.5651, consist-nmi:0.7840, consist-ari:0.4556, consist-p:0.5733, consist-fscore:0.5391\n",
            "[迭代 34/50]  consist-acc:0.5453, consist-nmi:0.7911, consist-ari:0.4655, consist-p:0.5401, consist-fscore:0.5074\n",
            "  💾 保存最佳模型: acc=0.5453, loss=834.0085\n",
            "[迭代 35/50]  consist-acc:0.5760, consist-nmi:0.7911, consist-ari:0.4593, consist-p:0.5904, consist-fscore:0.5537\n",
            "[迭代 36/50]  consist-acc:0.5651, consist-nmi:0.7914, consist-ari:0.4683, consist-p:0.5500, consist-fscore:0.5282\n",
            "[迭代 37/50]  consist-acc:0.5458, consist-nmi:0.7813, consist-ari:0.4419, consist-p:0.5560, consist-fscore:0.5161\n",
            "[迭代 38/50]  consist-acc:0.5776, consist-nmi:0.7899, consist-ari:0.4711, consist-p:0.5617, consist-fscore:0.5417\n",
            "  💾 保存最佳模型: acc=0.5776, loss=831.5032\n",
            "[迭代 39/50]  consist-acc:0.5469, consist-nmi:0.7879, consist-ari:0.4549, consist-p:0.5544, consist-fscore:0.5200\n",
            "  💾 保存最佳模型: acc=0.5469, loss=804.3795\n",
            "[迭代 40/50]  consist-acc:0.5365, consist-nmi:0.7808, consist-ari:0.4427, consist-p:0.5467, consist-fscore:0.5064\n",
            "  💾 保存最佳模型: acc=0.5365, loss=775.9882\n",
            "[迭代 41/50]  consist-acc:0.5448, consist-nmi:0.7837, consist-ari:0.4429, consist-p:0.5576, consist-fscore:0.5109\n",
            "[迭代 42/50]  consist-acc:0.5677, consist-nmi:0.7839, consist-ari:0.4561, consist-p:0.5963, consist-fscore:0.5460\n",
            "  💾 保存最佳模型: acc=0.5677, loss=737.2780\n",
            "[迭代 43/50]  consist-acc:0.5724, consist-nmi:0.7820, consist-ari:0.4473, consist-p:0.5877, consist-fscore:0.5498\n",
            "  💾 保存最佳模型: acc=0.5724, loss=709.6556\n",
            "[迭代 44/50]  consist-acc:0.5411, consist-nmi:0.7745, consist-ari:0.4415, consist-p:0.5505, consist-fscore:0.5154\n",
            "[迭代 45/50]  consist-acc:0.5568, consist-nmi:0.7899, consist-ari:0.4693, consist-p:0.5568, consist-fscore:0.5226\n",
            "[迭代 46/50]  consist-acc:0.5479, consist-nmi:0.7817, consist-ari:0.4404, consist-p:0.5404, consist-fscore:0.5122\n",
            "[迭代 47/50]  consist-acc:0.5635, consist-nmi:0.7866, consist-ari:0.4576, consist-p:0.5741, consist-fscore:0.5333\n",
            "[迭代 48/50]  consist-acc:0.5661, consist-nmi:0.7862, consist-ari:0.4628, consist-p:0.5755, consist-fscore:0.5400\n",
            "[迭代 49/50]  consist-acc:0.5531, consist-nmi:0.7781, consist-ari:0.4323, consist-p:0.5697, consist-fscore:0.5295\n",
            "[迭代 50/50]  consist-acc:0.5599, consist-nmi:0.7862, consist-ari:0.4631, consist-p:0.5422, consist-fscore:0.5248\n",
            "\n",
            "✅ View 1 训练完成！最佳准确率: 0.5724\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# View 1: 训练循环（50次评估）\n",
        "# ========================================\n",
        "\n",
        "result_dir = os.path.join(\"./last_sim_model\")\n",
        "os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "best_loss = np.inf\n",
        "best_acc = 0.\n",
        "old_best_model_path = \"\"\n",
        "acc = []\n",
        "\n",
        "for i in range(50):\n",
        "    # 加载数据\n",
        "    x_test, y_test = load_multiview(args.NUM_EX, False, train_dataset)\n",
        "    x_test, y_test = x_test[views].to(device), y_test.to(device)\n",
        "    \n",
        "    # 评估和适配\n",
        "    result, kmeans_pre, r_loss, c_loss, str_loss, cluster_center = accuracy_target(\n",
        "        source_center, source_result, model, x_test, y_test,\n",
        "        args.BATCH_SIZE, args.class_num, views, args.up_alpha, device=device\n",
        "    )\n",
        "    \n",
        "    cur_loss = r_loss + c_loss\n",
        "    acc.append(result['consist-acc'])\n",
        "    \n",
        "    print(f\"[迭代 {i+1}/50] \", ', '.join([f'{k}:{v:.4f}' for k, v in result.items()]))\n",
        "    \n",
        "    # 保存最佳模型\n",
        "    if cur_loss <= best_loss:\n",
        "        best_loss = cur_loss.item()\n",
        "        best_acc = result['consist-acc']\n",
        "        best_model_path = os.path.join(result_dir, f'last_sim_model--{int(views)}.pth')\n",
        "        if old_best_model_path and os.path.exists(old_best_model_path):\n",
        "            os.remove(old_best_model_path)\n",
        "        old_best_model_path = best_model_path\n",
        "        \n",
        "        np.save(f'./last_sim_model/last_sim_result.npy', kmeans_pre)\n",
        "        np.save(f'./last_sim_model/last_sim_center.npy', cluster_center)\n",
        "        model.eval()\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"  💾 保存最佳模型: acc={best_acc:.4f}, loss={best_loss:.4f}\")\n",
        "\n",
        "print(f\"\\n✅ View 1 训练完成！最佳准确率: {best_acc:.4f}\")\n",
        "np.save(f'./last_sim_model/acc-{int(views)}.npy', np.array(acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 步骤2：View 2 训练\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "开始 View 2 训练\n",
            "================================================================================\n",
            "✅ 已加载 View 1 的最佳模型\n",
            "✅ 已设置 CoTTA 模型\n",
            "✅ 已加载 View 1 的聚类先验\n",
            "\n",
            "开始训练 View 2...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# View 2: 从 View 1 的最佳模型继续训练\n",
        "# ========================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"开始 View 2 训练\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. 重新构建模型\n",
        "AE = ConsistencyAE(\n",
        "    basic_hidden_dim=32, c_dim=20, continous=True, in_channel=3, \n",
        "    num_res_blocks=3, ch_mult=[1, 2, 4, 8], block_size=8, temperature=1.0,\n",
        "    latent_ch=8, kld_weight=1.0, views=1, categorical_dim=args.class_num\n",
        ")\n",
        "\n",
        "# 2. 加载 View 1 的最佳模型\n",
        "AE.load_state_dict(\n",
        "    torch.load(f'./last_sim_model/last_sim_model--{1}.pth', map_location=device),\n",
        "    strict=False\n",
        ")\n",
        "base_model = AE.to(device)\n",
        "print(\"✅ 已加载 View 1 的最佳模型\")\n",
        "\n",
        "# 3. 设置适配模型\n",
        "model = setup_cotta_model(base_model)\n",
        "print(\"✅ 已设置 CoTTA 模型\")\n",
        "\n",
        "# 4. 加载 View 1 的聚类结果\n",
        "views = 2\n",
        "source_result = np.load(f'./last_sim_model/last_sim_result.npy')\n",
        "source_result = torch.from_numpy(source_result).to(device)\n",
        "source_center = np.load(f'./last_sim_model/last_sim_center.npy')\n",
        "print(\"✅ 已加载 View 1 的聚类先验\")\n",
        "\n",
        "print(\"\\n开始训练 View 2...\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[迭代 1/50]  consist-acc:0.1604, consist-nmi:0.4578, consist-ari:0.0442, consist-p:0.1663, consist-fscore:0.1571\n",
            "  💾 保存最佳模型: acc=0.1604, loss=11071.6484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\code\\VibeCoding\\ai-journey\\AdaptCMVC\\COIL100\\cotta.py:184: UserWarning: FALLBACK path has been taken inside: torch::jit::fuser::cuda::runCudaFusionGroup. This is an indication that codegen Failed for some reason.\n",
            "To debug try disable codegen fallback path via setting the env variable `export PYTORCH_NVFUSER_DISABLE=fallback`\n",
            " (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\jit\\codegen\\cuda\\manager.cpp:334.)\n",
            "  weight_consis_loss = self.consis * (sim_weight * softmax_entropy(z, outputs_ema.detach())).mean(0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[迭代 2/50]  consist-acc:0.3479, consist-nmi:0.6404, consist-ari:0.2173, consist-p:0.3370, consist-fscore:0.3290\n",
            "  💾 保存最佳模型: acc=0.3479, loss=8033.0083\n",
            "[迭代 3/50]  consist-acc:0.4094, consist-nmi:0.6776, consist-ari:0.2697, consist-p:0.4252, consist-fscore:0.3943\n",
            "  💾 保存最佳模型: acc=0.4094, loss=6589.2202\n",
            "[迭代 4/50]  consist-acc:0.4552, consist-nmi:0.7094, consist-ari:0.3313, consist-p:0.4471, consist-fscore:0.4312\n",
            "  💾 保存最佳模型: acc=0.4552, loss=5640.9917\n",
            "[迭代 5/50]  consist-acc:0.4792, consist-nmi:0.7291, consist-ari:0.3536, consist-p:0.4857, consist-fscore:0.4582\n",
            "  💾 保存最佳模型: acc=0.4792, loss=4939.5059\n",
            "[迭代 6/50]  consist-acc:0.5172, consist-nmi:0.7465, consist-ari:0.3880, consist-p:0.5187, consist-fscore:0.4982\n",
            "  💾 保存最佳模型: acc=0.5172, loss=4379.4268\n",
            "[迭代 7/50]  consist-acc:0.5453, consist-nmi:0.7655, consist-ari:0.4244, consist-p:0.5446, consist-fscore:0.5193\n",
            "  💾 保存最佳模型: acc=0.5453, loss=4006.1951\n",
            "[迭代 8/50]  consist-acc:0.5656, consist-nmi:0.7811, consist-ari:0.4431, consist-p:0.5760, consist-fscore:0.5435\n",
            "  💾 保存最佳模型: acc=0.5656, loss=3618.6218\n",
            "[迭代 9/50]  consist-acc:0.5625, consist-nmi:0.7807, consist-ari:0.4492, consist-p:0.5559, consist-fscore:0.5342\n",
            "  💾 保存最佳模型: acc=0.5625, loss=3380.8442\n",
            "[迭代 10/50]  consist-acc:0.5620, consist-nmi:0.7770, consist-ari:0.4304, consist-p:0.5683, consist-fscore:0.5321\n",
            "  💾 保存最佳模型: acc=0.5620, loss=3255.6367\n",
            "[迭代 11/50]  consist-acc:0.5714, consist-nmi:0.7833, consist-ari:0.4468, consist-p:0.5584, consist-fscore:0.5371\n",
            "  💾 保存最佳模型: acc=0.5714, loss=3130.1772\n",
            "[迭代 12/50]  consist-acc:0.5547, consist-nmi:0.7837, consist-ari:0.4382, consist-p:0.5590, consist-fscore:0.5277\n",
            "  💾 保存最佳模型: acc=0.5547, loss=2905.6804\n",
            "[迭代 13/50]  consist-acc:0.5510, consist-nmi:0.7780, consist-ari:0.4267, consist-p:0.5621, consist-fscore:0.5292\n",
            "  💾 保存最佳模型: acc=0.5510, loss=2771.9187\n",
            "[迭代 14/50]  consist-acc:0.5438, consist-nmi:0.7788, consist-ari:0.4276, consist-p:0.5487, consist-fscore:0.5190\n",
            "  💾 保存最佳模型: acc=0.5438, loss=2690.1213\n",
            "[迭代 15/50]  consist-acc:0.5677, consist-nmi:0.7833, consist-ari:0.4582, consist-p:0.5483, consist-fscore:0.5303\n",
            "  💾 保存最佳模型: acc=0.5677, loss=2560.4636\n",
            "[迭代 16/50]  consist-acc:0.5391, consist-nmi:0.7804, consist-ari:0.4389, consist-p:0.5337, consist-fscore:0.5051\n",
            "  💾 保存最佳模型: acc=0.5391, loss=2422.2939\n",
            "[迭代 17/50]  consist-acc:0.5443, consist-nmi:0.7783, consist-ari:0.4285, consist-p:0.5434, consist-fscore:0.5105\n",
            "  💾 保存最佳模型: acc=0.5443, loss=2337.6685\n",
            "[迭代 18/50]  consist-acc:0.5422, consist-nmi:0.7739, consist-ari:0.4185, consist-p:0.5500, consist-fscore:0.5122\n",
            "  💾 保存最佳模型: acc=0.5422, loss=2301.9194\n",
            "[迭代 19/50]  consist-acc:0.5401, consist-nmi:0.7752, consist-ari:0.4222, consist-p:0.5367, consist-fscore:0.5071\n",
            "[迭代 20/50]  consist-acc:0.5474, consist-nmi:0.7820, consist-ari:0.4331, consist-p:0.5348, consist-fscore:0.5128\n",
            "[迭代 21/50]  consist-acc:0.5385, consist-nmi:0.7824, consist-ari:0.4171, consist-p:0.5411, consist-fscore:0.5067\n",
            "  💾 保存最佳模型: acc=0.5385, loss=2221.1033\n",
            "[迭代 22/50]  consist-acc:0.5443, consist-nmi:0.7767, consist-ari:0.4249, consist-p:0.5526, consist-fscore:0.5189\n",
            "[迭代 23/50]  consist-acc:0.5609, consist-nmi:0.7829, consist-ari:0.4373, consist-p:0.5701, consist-fscore:0.5365\n",
            "[迭代 24/50]  consist-acc:0.5464, consist-nmi:0.7746, consist-ari:0.4228, consist-p:0.5571, consist-fscore:0.5220\n",
            "  💾 保存最佳模型: acc=0.5464, loss=2115.3159\n",
            "[迭代 25/50]  consist-acc:0.5542, consist-nmi:0.7819, consist-ari:0.4385, consist-p:0.5651, consist-fscore:0.5312\n",
            "  💾 保存最佳模型: acc=0.5542, loss=1981.4592\n",
            "[迭代 26/50]  consist-acc:0.5323, consist-nmi:0.7817, consist-ari:0.4277, consist-p:0.5441, consist-fscore:0.5031\n",
            "  💾 保存最佳模型: acc=0.5323, loss=1878.4005\n",
            "[迭代 27/50]  consist-acc:0.5708, consist-nmi:0.7930, consist-ari:0.4576, consist-p:0.5677, consist-fscore:0.5426\n",
            "  💾 保存最佳模型: acc=0.5708, loss=1778.5702\n",
            "[迭代 28/50]  consist-acc:0.5490, consist-nmi:0.7785, consist-ari:0.4246, consist-p:0.5444, consist-fscore:0.5158\n",
            "  💾 保存最佳模型: acc=0.5490, loss=1750.8701\n",
            "[迭代 29/50]  consist-acc:0.5427, consist-nmi:0.7798, consist-ari:0.4339, consist-p:0.5414, consist-fscore:0.5141\n",
            "  💾 保存最佳模型: acc=0.5427, loss=1749.1718\n",
            "[迭代 30/50]  consist-acc:0.5328, consist-nmi:0.7775, consist-ari:0.4220, consist-p:0.5473, consist-fscore:0.5054\n",
            "[迭代 31/50]  consist-acc:0.5375, consist-nmi:0.7901, consist-ari:0.4418, consist-p:0.5477, consist-fscore:0.5070\n",
            "[迭代 32/50]  consist-acc:0.5469, consist-nmi:0.7803, consist-ari:0.4308, consist-p:0.5566, consist-fscore:0.5247\n",
            "[迭代 33/50]  consist-acc:0.5594, consist-nmi:0.7877, consist-ari:0.4484, consist-p:0.5768, consist-fscore:0.5383\n",
            "[迭代 34/50]  consist-acc:0.5536, consist-nmi:0.7831, consist-ari:0.4438, consist-p:0.5613, consist-fscore:0.5286\n",
            "[迭代 35/50]  consist-acc:0.5641, consist-nmi:0.7905, consist-ari:0.4582, consist-p:0.5496, consist-fscore:0.5344\n",
            "  💾 保存最佳模型: acc=0.5641, loss=1704.7107\n",
            "[迭代 36/50]  consist-acc:0.5578, consist-nmi:0.7851, consist-ari:0.4555, consist-p:0.5564, consist-fscore:0.5333\n",
            "  💾 保存最佳模型: acc=0.5578, loss=1529.6614\n",
            "[迭代 37/50]  consist-acc:0.5464, consist-nmi:0.7826, consist-ari:0.4325, consist-p:0.5523, consist-fscore:0.5177\n",
            "  💾 保存最佳模型: acc=0.5464, loss=1378.9620\n",
            "[迭代 38/50]  consist-acc:0.5656, consist-nmi:0.7884, consist-ari:0.4630, consist-p:0.5576, consist-fscore:0.5302\n",
            "  💾 保存最佳模型: acc=0.5656, loss=1305.6571\n",
            "[迭代 39/50]  consist-acc:0.5797, consist-nmi:0.7883, consist-ari:0.4588, consist-p:0.5942, consist-fscore:0.5607\n",
            "  💾 保存最佳模型: acc=0.5797, loss=1266.9172\n",
            "[迭代 40/50]  consist-acc:0.5578, consist-nmi:0.7850, consist-ari:0.4450, consist-p:0.5566, consist-fscore:0.5303\n",
            "  💾 保存最佳模型: acc=0.5578, loss=1245.5687\n",
            "[迭代 41/50]  consist-acc:0.5781, consist-nmi:0.7884, consist-ari:0.4676, consist-p:0.5751, consist-fscore:0.5499\n",
            "  💾 保存最佳模型: acc=0.5781, loss=1242.7549\n",
            "[迭代 42/50]  consist-acc:0.5693, consist-nmi:0.7877, consist-ari:0.4626, consist-p:0.5714, consist-fscore:0.5400\n",
            "  💾 保存最佳模型: acc=0.5693, loss=1214.3405\n",
            "[迭代 43/50]  consist-acc:0.5698, consist-nmi:0.7959, consist-ari:0.4574, consist-p:0.5717, consist-fscore:0.5428\n",
            "[迭代 44/50]  consist-acc:0.5625, consist-nmi:0.7920, consist-ari:0.4631, consist-p:0.5554, consist-fscore:0.5335\n",
            "[迭代 45/50]  consist-acc:0.5568, consist-nmi:0.7834, consist-ari:0.4501, consist-p:0.5557, consist-fscore:0.5303\n",
            "  💾 保存最佳模型: acc=0.5568, loss=1199.0370\n",
            "[迭代 46/50]  consist-acc:0.5542, consist-nmi:0.7773, consist-ari:0.4424, consist-p:0.5637, consist-fscore:0.5314\n",
            "[迭代 47/50]  consist-acc:0.5604, consist-nmi:0.7916, consist-ari:0.4576, consist-p:0.5763, consist-fscore:0.5370\n",
            "[迭代 48/50]  consist-acc:0.5766, consist-nmi:0.7943, consist-ari:0.4691, consist-p:0.5837, consist-fscore:0.5511\n",
            "[迭代 49/50]  consist-acc:0.5479, consist-nmi:0.7857, consist-ari:0.4451, consist-p:0.5517, consist-fscore:0.5164\n",
            "[迭代 50/50]  consist-acc:0.5620, consist-nmi:0.7837, consist-ari:0.4580, consist-p:0.5473, consist-fscore:0.5264\n",
            "\n",
            "✅ View 2 训练完成！最佳准确率: 0.5568\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# View 2: 训练循环（50次评估）\n",
        "# ========================================\n",
        "\n",
        "result_dir = os.path.join(\"./last_sim_model\")\n",
        "os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "best_loss = np.inf\n",
        "best_acc = 0.\n",
        "old_best_model_path = \"\"\n",
        "acc_view2 = []\n",
        "\n",
        "for i in range(50):\n",
        "    # 加载数据\n",
        "    x_test, y_test = load_multiview(args.NUM_EX, False, train_dataset)\n",
        "    x_test, y_test = x_test[views].to(device), y_test.to(device)\n",
        "    \n",
        "    # 评估和适配\n",
        "    result, kmeans_pre, r_loss, c_loss, str_loss, cluster_center = accuracy_target(\n",
        "        source_center, source_result, model, x_test, y_test,\n",
        "        args.BATCH_SIZE, args.class_num, views, args.up_alpha, device=device\n",
        "    )\n",
        "    \n",
        "    cur_loss = r_loss + c_loss\n",
        "    acc_view2.append(result['consist-acc'])\n",
        "    \n",
        "    print(f\"[迭代 {i+1}/50] \", ', '.join([f'{k}:{v:.4f}' for k, v in result.items()]))\n",
        "    \n",
        "    # 保存最佳模型\n",
        "    if cur_loss <= best_loss:\n",
        "        best_loss = cur_loss.item()\n",
        "        best_acc = result['consist-acc']\n",
        "        best_model_path = os.path.join(result_dir, f'last_sim_model--{int(views)}.pth')\n",
        "        if old_best_model_path and os.path.exists(old_best_model_path):\n",
        "            os.remove(old_best_model_path)\n",
        "        old_best_model_path = best_model_path\n",
        "        \n",
        "        np.save(f'./last_sim_model/last_sim_result.npy', kmeans_pre)\n",
        "        np.save(f'./last_sim_model/last_sim_center.npy', cluster_center)\n",
        "        model.eval()\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"  💾 保存最佳模型: acc={best_acc:.4f}, loss={best_loss:.4f}\")\n",
        "\n",
        "print(f\"\\n✅ View 2 训练完成！最佳准确率: {best_acc:.4f}\")\n",
        "np.save(f'./last_sim_model/acc-{int(views)}.npy', np.array(acc_view2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 训练结果总结\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 加载并显示训练结果\n",
        "# ========================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 加载准确率历史\n",
        "acc_view1 = np.load('./last_sim_model/acc-1.npy')\n",
        "acc_view2 = np.load('./last_sim_model/acc-2.npy')\n",
        "\n",
        "# 绘制准确率曲线\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc_view1, label='View 1')\n",
        "plt.xlabel('迭代次数')\n",
        "plt.ylabel('准确率')\n",
        "plt.title('View 1 训练曲线')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(acc_view2, label='View 2')\n",
        "plt.xlabel('迭代次数')\n",
        "plt.ylabel('准确率')\n",
        "plt.title('View 2 训练曲线')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 打印最终结果\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"🎉 训练完成！\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"View 1 最佳准确率: {acc_view1.max():.4f}\")\n",
        "print(f\"View 2 最佳准确率: {acc_view2.max():.4f}\")\n",
        "print(\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "adapt-cmvc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
